{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTwpDNBnorUT"
      },
      "source": [
        "# ColBERTv2: Indexing & Search Notebook\n",
        "\n",
        "If you're working in Google Colab, we recommend selecting \"GPU\" as your hardware accelerator in the runtime settings.\n",
        "\n",
        "First, we'll import the relevant classes. Note that `Indexer` and `Searcher` are the key actors here. Next, we'll download the necessary dependencies."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================\n",
        "# 1️⃣ ColBERT deposunu klonla veya güncelle\n",
        "# =============================================\n",
        "!git clone https://github.com/stanford-futuredata/ColBERT.git || echo \"Already exists\"\n",
        "!cd ColBERT && git pull\n",
        "\n",
        "# =============================================\n",
        "# 2️⃣ Python yoluna ekle\n",
        "# =============================================\n",
        "import sys\n",
        "sys.path.insert(0, 'ColBERT')\n",
        "\n",
        "# =============================================\n",
        "# 3️⃣ Gerekli kütüphaneleri yükle (CUDA 12.4 uyumlu)\n",
        "# =============================================\n",
        "!pip install -U pip setuptools wheel\n",
        "!pip install torch==2.5.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install faiss-gpu==1.9.0.post1\n",
        "!pip install -e ColBERT/\n",
        "\n",
        "# =============================================\n",
        "# 4️⃣ Test – Kurulum başarılı mı kontrol et\n",
        "# =============================================\n",
        "from colbert import Indexer, Searcher\n",
        "print(\"✅ ColBERT başarıyla kuruldu ve import edildi!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl875Vuitvst",
        "outputId": "8c1438aa-54e7-400d-9368-39c8599769aa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ColBERT' already exists and is not an empty directory.\n",
            "Already exists\n",
            "Already up to date.\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (80.9.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (0.45.1)\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torch==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp312-cp312-linux_x86_64.whl (908.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.2/908.2 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m  \u001b[33m0:00:19\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m164.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m156.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m  \u001b[33m0:00:20\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m  \u001b[33m0:00:12\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m  \u001b[33m0:00:11\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m152.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1) (80.9.0)\n",
            "Collecting sympy==1.13.1 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp312-cp312-linux_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.1%2Bcu124-cp312-cp312-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m127.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.1%2Bcu124-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m116.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.5.1) (3.0.3)\n",
            "Installing collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "\u001b[2K  Attempting uninstall: triton\n",
            "\u001b[2K    Found existing installation: triton 2.2.0\n",
            "\u001b[2K    Uninstalling triton-2.2.0:\n",
            "\u001b[2K      Successfully uninstalled triton-2.2.0\n",
            "\u001b[2K  Attempting uninstall: sympy\n",
            "\u001b[2K    Found existing installation: sympy 1.13.3\n",
            "\u001b[2K    Uninstalling sympy-1.13.3:\n",
            "\u001b[2K      Successfully uninstalled sympy-1.13.3\n",
            "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
            "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
            "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.19.3\n",
            "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.19.3:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n",
            "\u001b[2K  Attempting uninstall: nvidia-curand-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
            "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
            "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
            "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
            "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
            "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
            "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
            "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
            "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
            "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
            "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
            "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n",
            "\u001b[2K    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
            "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
            "\u001b[2K  Attempting uninstall: torch\n",
            "\u001b[2K    Found existing installation: torch 2.2.0\n",
            "\u001b[2K    Uninstalling torch-2.2.0:\n",
            "\u001b[2K      Successfully uninstalled torch-2.2.0\n",
            "\u001b[2K  Attempting uninstall: torchvision\n",
            "\u001b[2K    Found existing installation: torchvision 0.23.0+cu126\n",
            "\u001b[2K    Uninstalling torchvision-0.23.0+cu126:\n",
            "\u001b[2K      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "\u001b[2K  Attempting uninstall: torchaudio\n",
            "\u001b[2K    Found existing installation: torchaudio 2.8.0+cu126\n",
            "\u001b[2K    Uninstalling torchaudio-2.8.0+cu126:\n",
            "\u001b[2K      Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [torchaudio]\n",
            "\u001b[1A\u001b[2KSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.1+cu124 torchaudio-2.5.1+cu124 torchvision-0.20.1+cu124 triton-3.1.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu==1.9.0.post1 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu==1.9.0.post1\u001b[0m\u001b[31m\n",
            "\u001b[0mObtaining file:///content/ColBERT\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: bitarray in /usr/local/lib/python3.12/dist-packages (from colbert-ai==0.2.22) (3.7.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from colbert-ai==0.2.22) (4.0.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (from colbert-ai==0.2.22) (3.1.2)\n",
            "Requirement already satisfied: GitPython in /usr/local/lib/python3.12/dist-packages (from colbert-ai==0.2.22) (3.1.45)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from colbert-ai==0.2.22) (1.1.1)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from colbert-ai==0.2.22) (1.13.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from colbert-ai==0.2.22) (1.16.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from colbert-ai==0.2.22) (4.67.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from colbert-ai==0.2.22) (4.57.1)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.12/dist-packages (from colbert-ai==0.2.22) (5.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai==0.2.22) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai==0.2.22) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai==0.2.22) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai==0.2.22) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai==0.2.22) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai==0.2.22) (2.32.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai==0.2.22) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai==0.2.22) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->colbert-ai==0.2.22) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai==0.2.22) (0.35.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai==0.2.22) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai==0.2.22) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->colbert-ai==0.2.22) (3.13.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->colbert-ai==0.2.22) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->colbert-ai==0.2.22) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->colbert-ai==0.2.22) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->colbert-ai==0.2.22) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->colbert-ai==0.2.22) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->colbert-ai==0.2.22) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->colbert-ai==0.2.22) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->colbert-ai==0.2.22) (3.11)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->colbert-ai==0.2.22) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets->colbert-ai==0.2.22) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets->colbert-ai==0.2.22) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets->colbert-ai==0.2.22) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets->colbert-ai==0.2.22) (2025.10.5)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask->colbert-ai==0.2.22) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask->colbert-ai==0.2.22) (8.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask->colbert-ai==0.2.22) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask->colbert-ai==0.2.22) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask->colbert-ai==0.2.22) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask->colbert-ai==0.2.22) (3.1.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from GitPython->colbert-ai==0.2.22) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->GitPython->colbert-ai==0.2.22) (5.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->colbert-ai==0.2.22) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->colbert-ai==0.2.22) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->colbert-ai==0.2.22) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->colbert-ai==0.2.22) (1.17.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->colbert-ai==0.2.22) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->colbert-ai==0.2.22) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->colbert-ai==0.2.22) (0.6.2)\n",
            "Installing collected packages: colbert-ai\n",
            "  Attempting uninstall: colbert-ai\n",
            "    Found existing installation: colbert-ai 0.2.22\n",
            "    Uninstalling colbert-ai-0.2.22:\n",
            "      Successfully uninstalled colbert-ai-0.2.22\n",
            "\u001b[33m  DEPRECATION: Legacy editable install of colbert-ai==0.2.22 from file:///content/ColBERT (setup.py develop) is deprecated. pip 25.3 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
            "\u001b[0m  Running setup.py develop for colbert-ai\n",
            "Successfully installed colbert-ai-0.2.22\n",
            "WARNING: faiss must be imported for indexing\n",
            "✅ ColBERT başarıyla kuruldu ve import edildi!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nl_YBBPTo5AZ",
        "outputId": "8e545ca9-1d63-4808-e59f-bae097527ecf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git -C ColBERT/ pull || git clone https://github.com/stanford-futuredata/ColBERT\n",
        "import sys; sys.path.insert(0, 'ColBERT/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmBi2UT5pxb3",
        "outputId": "4e6443f1-ae15-439c-9c22-0d6e151d86d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.2)\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 1.8.0.0, 1.8.0.1\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu-cu11==1.7.4 (from versions: 1.8.0.2, 1.9.0.0, 1.9.0.post1, 1.10.0, 1.11.0, 1.12.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu-cu11==1.7.4\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.1.0 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0, 2.9.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.1.0\u001b[0m\u001b[31m\n",
            "\u001b[0mObtaining file:///content/ColBERT\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: bitarray in /usr/local/lib/python3.12/dist-packages (from colbert-ai==0.2.22) (3.7.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from colbert-ai==0.2.22) (4.0.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (from colbert-ai==0.2.22) (3.1.2)\n",
            "Requirement already satisfied: GitPython in /usr/local/lib/python3.12/dist-packages (from colbert-ai==0.2.22) (3.1.45)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from colbert-ai==0.2.22) (1.1.1)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from colbert-ai==0.2.22) (1.13.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from colbert-ai==0.2.22) (1.16.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from colbert-ai==0.2.22) (4.67.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from colbert-ai==0.2.22) (4.35.0)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.12/dist-packages (from colbert-ai==0.2.22) (5.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai==0.2.22) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai==0.2.22) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai==0.2.22) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai==0.2.22) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai==0.2.22) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai==0.2.22) (2.32.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai==0.2.22) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai==0.2.22) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->colbert-ai==0.2.22) (2025.3.0)\n",
            "Collecting huggingface-hub>=0.24.0 (from datasets->colbert-ai==0.2.22)\n",
            "  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai==0.2.22) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets->colbert-ai==0.2.22) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->colbert-ai==0.2.22) (3.13.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->colbert-ai==0.2.22) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->colbert-ai==0.2.22) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->colbert-ai==0.2.22) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->colbert-ai==0.2.22) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->colbert-ai==0.2.22) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->colbert-ai==0.2.22) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->colbert-ai==0.2.22) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->colbert-ai==0.2.22) (3.11)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->colbert-ai==0.2.22) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets->colbert-ai==0.2.22) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets->colbert-ai==0.2.22) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets->colbert-ai==0.2.22) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets->colbert-ai==0.2.22) (2025.10.5)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask->colbert-ai==0.2.22) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask->colbert-ai==0.2.22) (8.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask->colbert-ai==0.2.22) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask->colbert-ai==0.2.22) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask->colbert-ai==0.2.22) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask->colbert-ai==0.2.22) (3.1.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from GitPython->colbert-ai==0.2.22) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->GitPython->colbert-ai==0.2.22) (5.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->colbert-ai==0.2.22) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->colbert-ai==0.2.22) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->colbert-ai==0.2.22) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->colbert-ai==0.2.22) (1.17.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->colbert-ai==0.2.22) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.12/dist-packages (from transformers->colbert-ai==0.2.22) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from transformers->colbert-ai==0.2.22) (0.6.2)\n",
            "INFO: pip is looking at multiple versions of tokenizers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers->colbert-ai==0.2.22)\n",
            "  Downloading tokenizers-0.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting transformers (from colbert-ai==0.2.22)\n",
            "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers->colbert-ai==0.2.22)\n",
            "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Downloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m169.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m128.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface-hub, tokenizers, transformers, colbert-ai\n",
            "\u001b[2K  Attempting uninstall: huggingface-hub\n",
            "\u001b[2K    Found existing installation: huggingface-hub 0.17.3\n",
            "\u001b[2K    Uninstalling huggingface-hub-0.17.3:\n",
            "\u001b[2K      Successfully uninstalled huggingface-hub-0.17.3\n",
            "\u001b[2K  Attempting uninstall: tokenizers\n",
            "\u001b[2K    Found existing installation: tokenizers 0.14.1\n",
            "\u001b[2K    Uninstalling tokenizers-0.14.1:\n",
            "\u001b[2K      Successfully uninstalled tokenizers-0.14.1\n",
            "\u001b[2K  Attempting uninstall: transformers\n",
            "\u001b[2K    Found existing installation: transformers 4.35.0\n",
            "\u001b[2K    Uninstalling transformers-4.35.0:\n",
            "\u001b[2K      Successfully uninstalled transformers-4.35.0\n",
            "\u001b[2K  Attempting uninstall: colbert-ai\n",
            "\u001b[2K    Found existing installation: colbert-ai 0.2.22\n",
            "\u001b[2K    Uninstalling colbert-ai-0.2.22:\n",
            "\u001b[2K      Successfully uninstalled colbert-ai-0.2.22\n",
            "   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [colbert-ai]\u001b[33m  DEPRECATION: Legacy editable install of colbert-ai==0.2.22 from file:///content/ColBERT (setup.py develop) is deprecated. pip 25.3 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
            "\u001b[2K  Running setup.py develop for colbert-ai\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [colbert-ai]\n",
            "\u001b[1A\u001b[2KSuccessfully installed colbert-ai-0.2.22 huggingface-hub-0.35.3 tokenizers-0.22.1 transformers-4.57.1\n"
          ]
        }
      ],
      "source": [
        "try: # When on google Colab, let's install all dependencies with pip.\n",
        "    import google.colab\n",
        "    !pip install -U pip\n",
        "    !pip install faiss-gpu-cu11==1.7.4\n",
        "    !pip install torch==2.1.0\n",
        "    !pip install -e ColBERT/\n",
        "except Exception:\n",
        "  import sys; sys.path.insert(0, 'ColBERT/')\n",
        "  try:\n",
        "    from colbert import Indexer, Searcher\n",
        "  except Exception:\n",
        "    print(\"If you're running outside Colab, please make sure you install ColBERT in conda following the instructions in our README. You can also install (as above) with pip but it may install slower or less stable faiss or torch dependencies. Conda is recommended.\")\n",
        "    assert False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "N0jxbVar4kln",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import colbert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xQg9A-dtp1nB"
      },
      "outputs": [],
      "source": [
        "from colbert import Indexer, Searcher\n",
        "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
        "from colbert.data import Queries, Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLWjmlkVq9r0"
      },
      "source": [
        "We will use the dev set of the **LoTTE benchmark** we recently introduced in the ColBERTv2 paper. We'll download it from HuggingFace datasets. The dev and test sets contain several domain-specific corpora, and we'll use the smallest dev set corpus, namely lifestyle:dev.\n",
        "\n",
        "For the purposes of a quick demo, we will only run the `Indexer` on the first 10,000 passages. As we do this, let's also remove the queries whose relevant passages are all outside this small set of passages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rF7lv8jvq-ut"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = 'lifestyle'\n",
        "datasplit = 'dev'\n",
        "\n",
        "collection_dataset = load_dataset(\"colbertv2/lotte_passages\", dataset)\n",
        "collection = [x['text'] for x in collection_dataset[datasplit + '_collection']]\n",
        "\n",
        "queries_dataset = load_dataset(\"colbertv2/lotte\", dataset)\n",
        "queries = [x['query'] for x in queries_dataset['search_' + datasplit]]\n",
        "\n",
        "f'Loaded {len(queries)} queries and {len(collection):,} passages'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXKC1oeUsnhk"
      },
      "source": [
        "This loaded 417 queries and 269k passages. Let's inspect one query and one passage to verify we have done so correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQFUHYTZs0aa",
        "outputId": "22f80aad-b6de-4df4-ffde-dd4b7718d78b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "are blossom end rot tomatoes edible?\n",
            "\n",
            "I think the spraying thing is not after, it's during. The cold will freeze the mist, keeping the air around the trees at (but not below) freezing. See http://www.ehow.com/how_5805520_use-freeze-damage-fruit-trees.html for example which recommends a sprinkler. The \"releases heat\" thing is kind of an oversimplification, but basically as long as you have any liquid water around, it will keep things at zero. The sap of your tree is not pure water, and therefore freezes somewhat below zero. By having the water freeze instead you stay away from the temps that would damage your plants. That said, http://www.ehow.com/how-does_5245655_spraying-frost-protect-fruit-freezing_.html is total gibberish since evaporation doesn't generate heat, quite the opposite. There is a better explanation at http://www.gardenguides.com/135830-spray-water-plants-during-frost.html This is a picture from a blog entry that gives you details from the citrus farmer's point of view.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(queries[24])\n",
        "print()\n",
        "print(collection[19929])\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKJdAAbDu7PZ"
      },
      "source": [
        "## Indexing\n",
        "\n",
        "For an efficient search, we can pre-compute the ColBERT representation of each passage and index them.\n",
        "\n",
        "Below, the `Indexer` take a model checkpoint and writes a (compressed) index to disk. We then prepare a `Searcher` for retrieval from this index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKAdVN5MvDKD"
      },
      "outputs": [],
      "source": [
        "nbits = 2   # encode each dimension with 2 bits\n",
        "doc_maxlen = 300 # truncate passages at 300 tokens\n",
        "max_id = 10000\n",
        "\n",
        "index_name = f'{dataset}.{datasplit}.{nbits}bits'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsImrM-rAUzi"
      },
      "source": [
        "To save space and time, we will only run the `Indexer` on the first 10,000 passages. To do so, we will filter out queries that do not contain passages with ids less than 10,000."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "kDkbZCvY_f7x",
        "outputId": "16b2c417-4fdd-447c-8fa6-0a67486d7c94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Filtered down to 20 queries'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "answer_pids = [x['answers']['answer_pids'] for x in queries_dataset['search_' + datasplit]]\n",
        "filtered_queries = [q for q, apids in zip(queries, answer_pids) if any(x < max_id for x in apids)]\n",
        "\n",
        "f'Filtered down to {len(filtered_queries)} queries'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orKfQRmQv46u"
      },
      "source": [
        "Now run the `Indexer` on the collection subset. Assuming the use of only one GPU, this cell should take about six minutes to finish running."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRiOnzxtwI0j",
        "outputId": "ddcd7c74-81fc-428d-b34a-3cdeb868c58d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "[Jun 28, 22:27:33] #> Creating directory /content/experiments/notebook/indexes/lifestyle.dev.2bits \n",
            "\n",
            "\n",
            "#> Starting...\n",
            "#> Joined...\n"
          ]
        }
      ],
      "source": [
        "checkpoint = 'colbert-ir/colbertv2.0'\n",
        "\n",
        "with Run().context(RunConfig(nranks=1, experiment='notebook')):  # nranks specifies the number of GPUs to use\n",
        "    config = ColBERTConfig(doc_maxlen=doc_maxlen, nbits=nbits, kmeans_niters=4) # kmeans_niters specifies the number of iterations of k-means clustering; 4 is a good and fast default.\n",
        "                                                                                # Consider larger numbers for small datasets.\n",
        "\n",
        "    indexer = Indexer(checkpoint=checkpoint, config=config)\n",
        "    indexer.index(name=index_name, collection=collection[:max_id], overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CTbP2LS1xHVZ",
        "outputId": "e20fed9f-14e8-4028-ec3b-34bba0a960c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/experiments/notebook/indexes/lifestyle.dev.2bits'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "indexer.get_index() # You can get the absolute path of the index, if needed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY6_D523yBFB"
      },
      "source": [
        "## Search\n",
        "\n",
        "Having built the index and prepared our `searcher`, we can search for individual query strings.\n",
        "\n",
        "We can use the `queries` set we loaded earlier — or you can supply your own questions. Feel free to get creative! But keep in mind this set of ~300k lifestyle passages can only answer a small, focused set of questions!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3x_FnVnyB0n",
        "outputId": "739b356b-cc76-4b30-8e1e-a150d8719cef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Jun 28, 22:34:54] #> Loading codec...\n",
            "[Jun 28, 22:34:54] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
            "[Jun 28, 22:34:54] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
            "[Jun 28, 22:34:55] #> Loading IVF...\n",
            "[Jun 28, 22:34:55] #> Loading doclens...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1261.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Jun 28, 22:34:55] #> Loading codes and residuals...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00, 10.74it/s]\n"
          ]
        }
      ],
      "source": [
        "# To create the searcher using its relative name (i.e., not a full path), set\n",
        "# experiment=value_used_for_indexing in the RunConfig.\n",
        "with Run().context(RunConfig(experiment='notebook')):\n",
        "    searcher = Searcher(index=index_name, collection=collection)\n",
        "\n",
        "\n",
        "# If you want to customize the search latency--quality tradeoff, you can also supply a\n",
        "# config=ColBERTConfig(ncells=.., centroid_score_threshold=.., ndocs=..) argument.\n",
        "# The default settings with k <= 10 (1, 0.5, 256) gives the fastest search,\n",
        "# but you can gain more extensive search by setting larger values of k or\n",
        "# manually specifying more conservative ColBERTConfig settings (e.g. (4, 0.4, 4096))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JYA0N22yIeS",
        "outputId": "7dda63ff-24e3-407b-fd2d-db74b8b27f48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#> are some cats just skinny?\n",
            "\n",
            "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
            "#> Input: . are some cats just skinny?, \t\t True, \t\t None\n",
            "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2024,  2070,  8870,  2074, 15629,  1029,   102,   103,\n",
            "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
            "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
            "          103,   103])\n",
            "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "\n",
            "\t [1] \t\t 24.1 \t\t A cat can certainly be naturally skinny. I know one who was the runt of her litter and has been extremely thin all her life, to the point where you can easily count every bone. She is now 17 years old, having outlived two other cats in that household, so it certainly doesn't seem to have held her back.\n",
            "\t [2] \t\t 24.0 \t\t Yes. Just like us, cats vary in size and shape and weight. And like us, some of that is diet, some is health, some is genetics, some is age. One of my lady's cats was the runt of the litter; it wasn't certain she would survive, and she has always been both small and skinny. It hasn't seemed to limit her climbing/jumping much, if at all; I think she benefits from square/cube law to be stronger relative to her weight than you would expect. Another cat in the family was not only longer/taller/broader but also more solidly muscled. I think he may have weighed twice what the small one did, without being overweight. (The simplest rule-of-thumb test for whether a cat is overweight: if you can count every vertibra as you run your hand down their back, they're fine. If some or all of them are hard to feel through the skin, there's probably more fat there than there should be. The runt really is below ideal weight; not only can you feel every bone in her back, it's somewhat hard to believe there are muscles and tendons there. Especially true now that she's a senior catizen.)\n",
            "\t [3] \t\t 22.1 \t\t Thank you for your question. You have a few different issues within your one question, but let's start with your main question regarding cats eating each other's food. I have the same problem with my cats. I have one cat who gorges herself, and I have one skinny cat who likes to graze all day long. What do you do with this situation? It is not easy. You have to get a little creative. And unfortunately you will likely never get to the point where they will only eat their own food. However, you can get to a point where they mostly eat their own food. One thing to note is that cats tend to be dominant over certain things. Cats are not usually dominant over everything, like dogs tend to be. Some cats are dominant over food, which it sounds like your cat is. My thin cat will not eat unless my overweight cat is eating. You can see the obvious dominance there. Here are some ideas for you... KEEPING CATS FROM EATING EACH OTHER'S FOOD I feed my cats wet food at night. I feed the slightly overweight cat in one place and my thin cat on a high shelf where she can see the other cat eating. During the day, I feed my overweight cat using an interactive feeder, so she has to use her natural instincts to work for her food. I give my skinny cat a small bowl of dry food on another shelf, so she can graze. It's not that my overweight cat can't get to the other food, but she is content to eat her easier-to-get food. Each morning, I also feed my skinny cat dry food in our closet, which is at the end of our walk-in bathroom. So there is quite a buffer from the bathroom door. I turn on the fan, so the other cat (who is closed out) cannot hear my skinny cat crunching. The things we do for our cats! I also sneak my skinny cat treats now and then. CATS EATING DOG FOOD This is a real problem for inside cats. You have to stop this. Even though your cats may be healthy now, eating dog food will make any cat overweight and unhealthy. I have volunteered at an animal shelter for many years and have seen this problem over and over again with overweight cats given to the shelter. Feed your dog at times you can supervise and take up the bowl when your dog is finished. If you kennel your dog, feed him in his kennel, so the cats can't get to the food. CAN CATS EAT VEGAN FOOD This is the most difficult part of your question because I can tell you have strong convictions in this area. However, I must tell you that cats should not ever be on a vegan diet. I am very sorry. I know this is difficult to hear. Cats were built to be obligate carnivores. They must have the taurine from the meat because they cannot produce it on their own, like dogs can. I know some vegan pet foods have synthetic taurine, but I wouldn't chance this. It is just not the same. Cats on a vegan diet will likely have severe medical conditions. See the quote below from Pet WebMD If allowed to continue long enough, these dietary problems can lead to serious and sometimes irreversible medical conditions. The one veterinarians mention most often is taurine-related dilated cardiomyopathy (enlarged heart with weak contractions and poor pumping ability). Low taurine can also lead to reproductive failures, growth failures, and eye problems. I hope this helps and at least gives you some ideas. I wish you and your animal family the best!\n"
          ]
        }
      ],
      "source": [
        "query = filtered_queries[13] # try with an in-range query or supply your own\n",
        "print(f\"#> {query}\")\n",
        "\n",
        "# Find the top-3 passages for this query\n",
        "results = searcher.search(query, k=3)\n",
        "\n",
        "# Print out the top-k retrieved passages\n",
        "for passage_id, passage_rank, passage_score in zip(*results):\n",
        "    print(f\"\\t [{passage_rank}] \\t\\t {passage_score:.1f} \\t\\t {searcher.collection[passage_id]}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}